{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "One problem that often arises with Linear Regression (and all machine learning algorithms) is overfitting on training data. The workhorse optimization function converges on weights that minimize the cost function *too* much. To deal with this, we add a term to the cost function which penalizes the weights by adding a metric onto the sum of squared error terms. This metric is commonly the *L-1* or *L-2* norm, named **Lasso** and **Ridge** respectively. We now present a class that updates the simple regression class with a choice of regularization to prevent overfitting. \n",
    "\n",
    "A quick note, with Ridge regression, we shrink the coefficients and it helps to reduce the model complexity and multi-collinearity using the $L_2$ norm of the weights times a $\\lambda$. So if we set $\\lambda=0$, we have the same cost function as in normal linear regression. As $\\lambda$ gets bigger, the weights are penalized more. In Lasso regression, the process is identical but uses the $L_1$ norm. The important distinction is that Lasso tends to zero out non relevant features much more than ridge, so it can be useful in feature selection.\n",
    "\n",
    "In this algorithm, we provide a new feature for the model which evaluates the predictive power of the linear regression on unseen test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionRegularization():\n",
    "    \n",
    "    def __init__(self, learning_rate):\n",
    "        '''Initializes the class with a learning rate for the optimization of weights.'''\n",
    "        self.learning_rate = learning_rate\n",
    "          \n",
    "    def fit(self, train_data, train_target, regularization, lambda_):\n",
    "        '''Input the training data and its respective target values'''\n",
    "        \n",
    "        #Convert data to numpy arrays\n",
    "        X = np.concatenate((np.array([np.zeros(len(train_data))+1]).T, train_data), axis = 1)\n",
    "        y = np.array(train_target)\n",
    "        \n",
    "        #initialize coefficients\n",
    "        coefficients = np.random.normal(0, 1, X.shape[1])\n",
    "        self.coefficients = coefficients\n",
    "        \n",
    "        #Keep a list of SSE and MSE for each iteration if you desire to analyze\n",
    "        \n",
    "        self.SSE_list = []\n",
    "        self.MSE_list = []\n",
    "            \n",
    "        #Define different regularizations\n",
    "        def regularization_function(weights):\n",
    "            if regularization == 'None':\n",
    "                return 0\n",
    "            if regularization == 'Lasso':\n",
    "                sign_func = lambda x: 1 if x >= 0 else -1\n",
    "                return lambda_ * np.array([sign_func(wi) for wi in weights])\n",
    "            if regularization == 'Ridge':\n",
    "                return lambda_ * 2 * weights\n",
    "                \n",
    "        #iteratively improve coefficients:\n",
    "        i = 0\n",
    "        while i < 1000:\n",
    "            predict = np.matmul(X, self.coefficients)\n",
    "            SSE = np.linalg.norm(y-predict)\n",
    "            MSE = SSE/X.shape[0]\n",
    "            self.SSE_list.append(SSE)\n",
    "            self.MSE_list.append(MSE)\n",
    "            \n",
    "            #Calculate the gradient of SSE with regularization and apply some randomness\n",
    "            gradient = -(1/SSE) * np.matmul((y-predict).T, X)+regularization_function(self.coefficients) + np.random.normal(0, 1, self.coefficients.shape)\n",
    "            self.coefficients = self.coefficients - (1/(i+1))*self.learning_rate * gradient\n",
    "            i += 1\n",
    "        SStotal = np.sum((y - np.mean(y))**2)\n",
    "        self.intercept = self.coefficients[0]\n",
    "        self.weights = self.coefficients[1:]\n",
    "        self.error_analysis = pd.DataFrame({'Sum of Squared Errors': [self.SSE_list[-1]],\n",
    "                                           'Mean Squared Error': [self.MSE_list[-1]],\n",
    "                                           'Root Mean Squared Error': [np.sqrt(self.MSE_list[-1])],\n",
    "                                           'R-squared': [1-self.SSE_list[-1]/SStotal]})\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_test,y_test):\n",
    "        '''Inputs are unseen test data and respective targets.'''\n",
    "        X = np.concatenate((np.array([np.zeros(len(X_test))+1]).T, X_test), axis = 1)\n",
    "        y = np.array(y_test)\n",
    "        \n",
    "        self.predictions = np.matmul(X, self.coefficients)\n",
    "        SStotal = np.sum((y - np.mean(y))**2)\n",
    "        self.SSE = np.linalg.norm(y-self.predictions)\n",
    "        self.MSE = MSE = self.SSE/X.shape[0]\n",
    "        self.test_error = pd.DataFrame({'Sum of Squared Errors': [self.SSE],\n",
    "                                   'Mean Squared Error': [self.MSE],\n",
    "                                   'Root Mean Squared Error': [np.sqrt(self.MSE)],\n",
    "                                   'R-squared': [1-self.SSE/SStotal]}, index = [\"Test Data Metrics\"])\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to fit a linear regression to our model. Note that the column we defined does not effect our target at all. We will test the different regression functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.DataFrame({'a': 10*np.random.normal(0,1, 1000), 'b': 5*np.random.normal(0,1, 1000), \n",
    "                           'c': 2*np.random.normal(0,1, 1000)})\n",
    "sample_data['target'] = 2*(sample_data['a']+sample_data['b']) + 10 + 30*np.random.normal(0,1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionRegularization(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegressionRegularization at 0x7fe8e3737b50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sample_data[['a','b', 'c']], sample_data['target'], 'None', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.93405345,  1.97667421, -0.07084178])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.2837403600485855"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sum of Squared Errors</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955.474127</td>\n",
       "      <td>0.955474</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>0.999292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sum of Squared Errors  Mean Squared Error  Root Mean Squared Error  \\\n",
       "0             955.474127            0.955474                 0.977484   \n",
       "\n",
       "   R-squared  \n",
       "0   0.999292  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegressionRegularization at 0x7fe8e37be210>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = LinearRegressionRegularization(0.2)\n",
    "ridge_model.fit(sample_data[['a','b', 'c']], sample_data['target'], 'Ridge', 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.90651198,  1.85566253, -0.0380647 ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7645150561860645"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sum of Squared Errors</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>966.524918</td>\n",
       "      <td>0.966525</td>\n",
       "      <td>0.98312</td>\n",
       "      <td>0.999284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sum of Squared Errors  Mean Squared Error  Root Mean Squared Error  \\\n",
       "0             966.524918            0.966525                  0.98312   \n",
       "\n",
       "   R-squared  \n",
       "0   0.999284  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegressionRegularization at 0x7fe8e3891290>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = LinearRegressionRegularization(0.2)\n",
    "lasso_model.fit(sample_data[['a','b', 'c']], sample_data['target'], 'Lasso', 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.92521770e+00,  1.94289142e+00, -2.82950403e-05])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.113898144897629"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sum of Squared Errors</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>956.035073</td>\n",
       "      <td>0.956035</td>\n",
       "      <td>0.97777</td>\n",
       "      <td>0.999292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sum of Squared Errors  Mean Squared Error  Root Mean Squared Error  \\\n",
       "0             956.035073            0.956035                  0.97777   \n",
       "\n",
       "   R-squared  \n",
       "0   0.999292  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.error_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So although the model was best using standard linear regression, we should note that the whole point is to make sure that we aren't overfitting the data. That means the training data obviously is going to have the best score when we use normal linear regression. Note one cool thing however, Lasso did exactly what we thought it would with the feature c, which we purposefully left out. It correctly sent it the closest to zero by far. In this sense, Lasso helped us choose only the features that were important."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
