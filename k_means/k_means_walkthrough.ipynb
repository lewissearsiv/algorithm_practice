{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "#### Lew Sears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Means_Clustering:\n",
    "    '''Basic k-means algorithm for cluster analysis. '''\n",
    "    \n",
    "    #initialize the hyperparameter k\n",
    "    def __init__(self, k):\n",
    "        try:\n",
    "            if type(k) == int and k >= 1:\n",
    "                self.k = k\n",
    "            else:\n",
    "                raise ValueError('Bad k')\n",
    "        except ValueError as exp:\n",
    "            line = \"\\n---------------------------------------\\n\"\n",
    "            print(\"Value Error:{}Given k = {}. Bad choice my friend!{}k must be a nonzero positive integer.{}\\\n",
    "            \".format(line, k, line, line))\n",
    "    \n",
    "    #Find the best centroids to create labels\n",
    "    def fit(self, df, iterations):\n",
    "        '''Input a scaled np.array with only numerical columns to be assigned labels. For a pandas dataframe,\n",
    "        just fit StandardScaler and transform the dataframe. Put in the amount of iterations you desire. The\n",
    "        iterations will stop if the labels do not change.'''\n",
    "        \n",
    "        #We will run through this process based on the set ammount of iterations.\n",
    "        iteration_counter = 0\n",
    "        while iteration_counter < iterations:\n",
    "            \n",
    "            #Initialize centroids\n",
    "            if iteration_counter == 0:\n",
    "                #df is scaled so we just want random points normally distibuted around 0\n",
    "                centroids = np.random.normal(0 , 1, size = (self.k,df.shape[1]))\n",
    "            #Update centroids\n",
    "            else:\n",
    "                centroids = centroids_update\n",
    "\n",
    "\n",
    "            #Pick the labels\n",
    "            closest_centroid = []\n",
    "            for vec in df:\n",
    "                distances = np.sum((centroids - vec)**2, axis = 1)\n",
    "                label = np.argmin(distances)\n",
    "                closest_centroid.append(label)\n",
    "            labels = np.array(closest_centroid)\n",
    "\n",
    "            #Now calculate new centroids\n",
    "            updates = []\n",
    "            unique_labels = np.unique(labels)\n",
    "            for some_label in unique_labels:\n",
    "                some_label_group = df[labels == some_label]\n",
    "                \n",
    "                #Find the average\n",
    "                try: \n",
    "                    center = np.sum(some_label_group, axis = 0)/some_label_group.shape[0]\n",
    "                    \n",
    "                #This is basically the case where there are no points with this label\n",
    "                except:\n",
    "                    center = np.random.normal(0 , 1, size = (5,)) \n",
    "                \n",
    "                updates.append(center)\n",
    "            centroids_update = np.array(updates)\n",
    "            iteration_counter += 1\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36177393,  0.37052257, -0.57885455, -0.39851214, -0.28042686],\n",
       "       [ 0.36549238, -1.4428312 ,  0.24433438, -0.74179752,  2.1499628 ],\n",
       "       [-1.36458607,  1.98729012,  0.63874237, -0.561706  , -0.18450669],\n",
       "       [ 0.15971166,  0.5011711 ,  0.7094652 , -1.3826558 ,  0.04625263],\n",
       "       [ 0.54021006, -0.4239882 , -0.77850737, -1.66727699,  0.16915566]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = np.random.normal(0 , 1, size = (100,5))\n",
    "sample_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = K_Means_Clustering(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.fit(sample_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), array([19, 23, 24, 17, 17]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(a, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 2, 0, 1, 0, 3, 4, 1, 4, 0, 1, 2, 1, 2, 3, 4, 2, 0, 2, 0,\n",
       "       3, 1, 4, 0, 2, 4, 2, 3, 2, 2, 2, 3, 4, 2, 2, 1, 0, 0, 2, 1, 0, 0,\n",
       "       3, 1, 0, 1, 0, 4, 4, 3, 0, 0, 2, 3, 3, 0, 0, 1, 2, 1, 3, 1, 1, 4,\n",
       "       2, 4, 2, 1, 0, 1, 3, 4, 2, 4, 4, 3, 1, 1, 1, 1, 2, 3, 4, 1, 0, 4,\n",
       "       2, 2, 1, 0, 3, 2, 4, 3, 4, 2, 1, 3])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
