{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting for Regression\n",
    "#### Lewis Sears\n",
    "\n",
    "Using tree based methods for regression, we now will write an algorithm that predicts continuous data using a method called gradient boosting.\n",
    "\n",
    "Before the algorithm, why don't we just observe how much more powerful the gradient boosted regressor actually is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real estate data for testing\n",
    "df = pd.read_csv('car_data.csv')\n",
    "df_cars = df[['Year', 'Selling_Price', 'Kms_Driven','Owner']]\n",
    "target = df['Present_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble as ml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_cars, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = ml.GradientBoostingRegressor(loss = 'ls', learning_rate = 0.75, n_estimators = 2, max_depth = 1000)\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_scores = gbr.score(X_train, y_train), gbr.score(X_test, y_test)\n",
    "reg_scores = lr.score(X_train, y_train), lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9960778195129079, 0.8458376639057927)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8504954757170343, 0.7991031805544824)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, even though it overfit the training data, the boosted tree regressor far outperformed standard linear regression. It is a much more powerful algorithm than simply minimizing squared error of residuals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "class GradientBoostedRegression(object):\n",
    "    '''Our boosted regression algorithm using tree based regression models.'''\n",
    "    \n",
    "    def __init__(self, learning_rate, tree_depth):\n",
    "        '''\n",
    "        Some initial Hyper parameters:\n",
    "        learning_rate: A number between 0 and 1 that scales the added output of a new tree\n",
    "        tree_depth: The number of trees will we stack together \n",
    "        '''\n",
    "        self.learning_rate = learning_rate\n",
    "        self.depth = tree_depth                          \n",
    "\n",
    "    #define the loss function                  \n",
    "    def Loss_Function(target, predicted):\n",
    "        return 0.5*np.sum((target-predicted))**2\n",
    "    #The derivative is really straightforward\n",
    "    def derivative_loss_function(target, predicted):\n",
    "        return -(target - predicted)\n",
    "        \n",
    "    def fit(self, train_data, train_target):\n",
    "        '''Since this is a regression algorithm, the train_target should be a good continuous target.'''\n",
    "        \n",
    "        data = np.array(train_data)\n",
    "        target = np.array(train_target)\n",
    "        \n",
    "        #initialize residuals:\n",
    "        residuals = target - np.mean(target)\n",
    "        \n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
